# üìã –≠–¢–ê–ü 6: INFRASTRUCTURE - DOCKER & DEPLOYMENT
# Freqtrade Multi-Bot System - Production Infrastructure

**–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:** 4 —á–∞—Å–∞
**–¶–µ–ª—å:** Production-ready Docker –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞ —Å monitoring

---

## üéØ –ó–ê–î–ê–ß–ò –≠–¢–ê–ü–ê

### ‚úÖ –ó–∞–¥–∞—á–∞ 6.1: Docker Compose –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞ (2 —á–∞—Å–∞)
- –ù–∞—Å—Ç—Ä–æ–∏—Ç—å production-ready Docker Compose
- –î–æ–±–∞–≤–∏—Ç—å health checks –∏ resource limits
- –ù–∞—Å—Ç—Ä–æ–∏—Ç—å networking –∏ volumes

### ‚úÖ –ó–∞–¥–∞—á–∞ 6.2: Monitoring & Observability (1 —á–∞—Å)
- Prometheus + Grafana –¥–ª—è –º–µ—Ç—Ä–∏–∫
- Loki + Promtail –¥–ª—è –ª–æ–≥–æ–≤
- Alert rules –¥–ª—è critical events

### ‚úÖ –ó–∞–¥–∞—á–∞ 6.3: Nginx Reverse Proxy (0.5 —á–∞—Å–∞)
- SSL/TLS –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
- Rate limiting –∏ security headers
- Load balancing

### ‚úÖ –ó–∞–¥–∞—á–∞ 6.4: Backup & Recovery (0.5 —á–∞—Å–∞)
- Automated backups to S3
- Database –∏ user data backup
- Recovery procedures

---

## üöÄ –î–ï–¢–ê–õ–¨–ù–ê–Ø –†–ï–ê–õ–ò–ó–ê–¶–ò–Ø

### 1. Docker Compose Infrastructure (2 —á–∞—Å–∞)
**docker-compose.yml:**
```yaml
version: '3.8'

services:
  # Core API Server
  api:
    build:
      context: .
      dockerfile: Dockerfile.api
    container_name: freqtrade_api
    restart: unless-stopped
    ports:
      - "8000:8000"
    environment:
      - ENVIRONMENT=production
      - DATABASE_URL=postgresql://freqtrade:password@db:5432/freqtrade
      - REDIS_URL=redis://redis:6379/0
      - SECRET_KEY=${SECRET_KEY}
      - JWT_SECRET=${JWT_SECRET}
    volumes:
      - ./user_data:/app/user_data
      - ./logs:/app/logs
    depends_on:
      - db
      - redis
    networks:
      - freqtrade_network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M

  # Database
  db:
    image: postgres:15-alpine
    container_name: freqtrade_db
    restart: unless-stopped
    environment:
      - POSTGRES_DB=freqtrade
      - POSTGRES_USER=freqtrade
      - POSTGRES_PASSWORD=${DB_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./db/init.sql:/docker-entrypoint-initdb.d/init.sql
    ports:
      - "5432:5432"
    networks:
      - freqtrade_network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U freqtrade"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Redis Cache & Streams (–º–µ–∂—Å–µ—Ä–≤–∏—Å–Ω–∞—è —Å–≤—è–∑—å)
  redis:
    image: redis:7-alpine
    container_name: freqtrade_redis
    restart: unless-stopped
    command: >
      redis-server
      --appendonly yes
      --requirepass ${REDIS_PASSWORD}
      --stream-max-len 10000
      --stream-node-max-entries 1000
      --maxmemory 512mb
      --maxmemory-policy allkeys-lru
    volumes:
      - redis_data:/data
    ports:
      - "6379:6379"
    networks:
      - freqtrade_network
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
    environment:
      - REDIS_PASSWORD=${REDIS_PASSWORD}

  # Frontend
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile.frontend
    container_name: freqtrade_frontend
    restart: unless-stopped
    ports:
      - "80:80"
    environment:
      - VITE_API_BASE_URL=http://api:8000
      - VITE_WS_BASE_URL=http://api:8000
    depends_on:
      - api
    networks:
      - freqtrade_network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Nginx Reverse Proxy
  nginx:
    image: nginx:alpine
    container_name: freqtrade_nginx
    restart: unless-stopped
    ports:
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
      - nginx_logs:/var/log/nginx
    depends_on:
      - api
      - frontend
    networks:
      - freqtrade_network

  # Monitoring Stack
  prometheus:
    image: prom/prometheus:latest
    container_name: freqtrade_prometheus
    restart: unless-stopped
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
    networks:
      - freqtrade_network

  grafana:
    image: grafana/grafana:latest
    container_name: freqtrade_grafana
    restart: unless-stopped
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD}
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning:ro
      - ./monitoring/grafana/dashboards:/var/lib/grafana/dashboards:ro
    depends_on:
      - prometheus
    networks:
      - freqtrade_network

  # Log Aggregation
  loki:
    image: grafana/loki:latest
    container_name: freqtrade_loki
    restart: unless-stopped
    ports:
      - "3100:3100"
    volumes:
      - ./monitoring/loki-config.yml:/etc/loki/local-config.yaml:ro
      - loki_data:/loki
    command: -config.file=/etc/loki/local-config.yaml
    networks:
      - freqtrade_network

  promtail:
    image: grafana/promtail:latest
    container_name: freqtrade_promtail
    restart: unless-stopped
    volumes:
      - ./monitoring/promtail-config.yml:/etc/promtail/config.yml:ro
      - /var/log/containers:/var/log/containers:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
    command: -config.file=/etc/promtail/config.yml
    depends_on:
      - loki
    networks:
      - freqtrade_network

  # Backup Service
  backup:
    build:
      context: .
      dockerfile: Dockerfile.backup
    container_name: freqtrade_backup
    restart: unless-stopped
    environment:
      - BACKUP_INTERVAL=24h
      - BACKUP_RETENTION=30
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - S3_BUCKET=${S3_BUCKET}
    volumes:
      - ./user_data:/app/user_data:ro
      - ./backups:/app/backups
    depends_on:
      - db
    networks:
      - freqtrade_network

networks:
  freqtrade_network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16

volumes:
  postgres_data:
  redis_data:
  prometheus_data:
  grafana_data:
  loki_data:
  nginx_logs:
```

**Dockerfile.api:**
```dockerfile
FROM python:3.11-slim

# Set environment variables
ENV PYTHONUNBUFFERED=1
ENV PYTHONDONTWRITEBYTECODE=1
ENV PYTHONPATH=/app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    libpq-dev \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Create app user
RUN useradd --create-home --shell /bin/bash app

# Set work directory
WORKDIR /app

# Copy requirements first for better caching
COPY requirements.txt .
RUN uv pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY . .

# Change ownership
RUN chown -R app:app /app

# Switch to app user
USER app

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# Expose port
EXPOSE 8000

# Run application
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000", "--workers", "4"]
```

### 2. Monitoring & Observability (1 —á–∞—Å)
**monitoring/prometheus.yml:**
```yaml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  - "alert_rules.yml"

alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - alertmanager:9093

scrape_configs:
  - job_name: 'freqtrade-api'
    static_configs:
      - targets: ['api:8000']
    metrics_path: '/metrics'
    scrape_interval: 5s

  - job_name: 'freqtrade-frontend'
    static_configs:
      - targets: ['frontend:80']
    metrics_path: '/metrics'
    scrape_interval: 15s

  - job_name: 'postgres'
    static_configs:
      - targets: ['db:5432']
    scrape_interval: 30s

  - job_name: 'redis'
    static_configs:
      - targets: ['redis:6379']
    scrape_interval: 30s

  - job_name: 'docker'
    static_configs:
      - targets: ['docker-exporter:9323']
    scrape_interval: 30s

  - job_name: 'node-exporter'
    static_configs:
      - targets: ['node-exporter:9100']
    scrape_interval: 30s
```

**monitoring/alert_rules.yml:**
```yaml
groups:
  - name: freqtrade_alerts
    rules:
      - alert: HighErrorRate
        expr: rate(http_requests_total{status=~"5.."}[5m]) / rate(http_requests_total[5m]) > 0.05
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value }}%"

      - alert: BotDown
        expr: up{job="freqtrade-api"} == 0
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "Freqtrade API is down"
          description: "Freqtrade API has been down for more than 2 minutes"

      - alert: HighMemoryUsage
        expr: (1 - node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes) * 100 > 85
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High memory usage"
          description: "Memory usage is {{ $value }}%"

      - alert: DatabaseConnectionIssues
        expr: pg_stat_activity_count{datname="freqtrade"} > 100
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "High database connections"
          description: "Database has {{ $value }} active connections"
```

### 3. Nginx Configuration (0.5 —á–∞—Å–∞)
**nginx/nginx.conf:**
```nginx
events {
    worker_connections 1024;
}

http {
    include /etc/nginx/mime.types;
    default_type application/octet-stream;

    # Logging
    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for"';

    access_log /var/log/nginx/access.log main;
    error_log /var/log/nginx/error.log;

    # Performance
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    types_hash_max_size 2048;
    client_max_body_size 100M;

    # Gzip compression
    gzip on;
    gzip_vary on;
    gzip_min_length 1024;
    gzip_proxied any;
    gzip_comp_level 6;
    gzip_types
        text/plain
        text/css
        text/xml
        text/javascript
        application/json
        application/javascript
        application/xml+rss
        application/atom+xml
        image/svg+xml;

    # Rate limiting
    limit_req_zone $binary_remote_addr zone=api:10m rate=10r/s;
    limit_req_zone $binary_remote_addr zone=frontend:10m rate=100r/s;

    upstream api_backend {
        server api:8000;
    }

    upstream frontend_backend {
        server frontend:80;
    }

    server {
        listen 80;
        server_name _;

        # Redirect to HTTPS
        return 301 https://$server_name$request_uri;
    }

    server {
        listen 443 ssl http2;
        server_name your-domain.com;

        # SSL configuration
        ssl_certificate /etc/nginx/ssl/cert.pem;
        ssl_certificate_key /etc/nginx/ssl/key.pem;
        ssl_protocols TLSv1.2 TLSv1.3;
        ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384;
        ssl_prefer_server_ciphers off;

        # Security headers
        add_header X-Frame-Options "SAMEORIGIN" always;
        add_header X-XSS-Protection "1; mode=block" always;
        add_header X-Content-Type-Options "nosniff" always;
        add_header Referrer-Policy "no-referrer-when-downgrade" always;
        add_header Content-Security-Policy "default-src 'self' http: https: data: blob: 'unsafe-inline'" always;

        # Frontend
        location / {
            limit_req zone=frontend burst=20 nodelay;

            proxy_pass http://frontend_backend;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;

            # WebSocket support
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection "upgrade";
        }

        # API
        location /api/ {
            limit_req zone=api burst=10 nodelay;

            proxy_pass http://api_backend;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;

            # WebSocket support for API
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection "upgrade";
        }

        # Static files caching
        location ~* \.(js|css|png|jpg|jpeg|gif|ico|svg)$ {
            expires 1y;
            add_header Cache-Control "public, immutable";
        }

        # Health check
        location /health {
            access_log off;
            return 200 "healthy\n";
            add_header Content-Type text/plain;
        }
    }
}
```

### 4. Backup & Recovery System (0.5 —á–∞—Å–∞)
**Dockerfile.backup:**
```dockerfile
FROM alpine:latest

# Install dependencies
RUN apk add --no-cache \
    postgresql-client \
    redis \
    aws-cli \
    curl \
    bash

# Copy backup script
COPY backup.sh /usr/local/bin/backup.sh
RUN chmod +x /usr/local/bin/backup.sh

# Create backup directories
RUN mkdir -p /app/backups /app/user_data

# Set work directory
WORKDIR /app

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# Run backup script
CMD ["/usr/local/bin/backup.sh"]
```

**backup.sh:**
```bash
#!/bin/bash

set -e

# Configuration
BACKUP_DIR="/app/backups"
TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
BACKUP_RETENTION=${BACKUP_RETENTION:-30}

# Database backup
echo "Creating database backup..."
pg_dump -h db -U freqtrade freqtrade > "${BACKUP_DIR}/db_${TIMESTAMP}.sql"

# Redis backup
echo "Creating Redis backup..."
redis-cli -h redis -a "${REDIS_PASSWORD}" --rdb "${BACKUP_DIR}/redis_${TIMESTAMP}.rdb"

# User data backup
echo "Creating user data backup..."
tar -czf "${BACKUP_DIR}/user_data_${TIMESTAMP}.tar.gz" -C /app user_data

# Upload to S3 if configured
if [ -n "${AWS_ACCESS_KEY_ID}" ] && [ -n "${S3_BUCKET}" ]; then
    echo "Uploading backups to S3..."
    aws s3 cp "${BACKUP_DIR}/" "s3://${S3_BUCKET}/backups/" --recursive --exclude "*" --include "*.sql" --include "*.rdb" --include "*.tar.gz"
fi

# Cleanup old backups
echo "Cleaning up old backups..."
find "${BACKUP_DIR}" -name "*.sql" -mtime +${BACKUP_RETENTION} -delete
find "${BACKUP_DIR}" -name "*.rdb" -mtime +${BACKUP_RETENTION} -delete
find "${BACKUP_DIR}" -name "*.tar.gz" -mtime +${BACKUP_RETENTION} -delete

# Cleanup S3 if configured
if [ -n "${AWS_ACCESS_KEY_ID}" ] && [ -n "${S3_BUCKET}" ]; then
    aws s3 ls "s3://${S3_BUCKET}/backups/" | while read -r line; do
        createDate=$(echo "$line" | awk {'print $1" "$2'})
        createDate=$(date -d"$createDate" +%s)
        olderThan=$(date -d"${BACKUP_RETENTION} days ago" +%s)
        if [[ $createDate -lt $olderThan ]]; then
            fileName=$(echo "$line" | awk {'print $4'})
            if [[ $fileName != "" ]]; then
                aws s3 rm "s3://${S3_BUCKET}/backups/$fileName"
            fi
        fi
    done
fi

echo "Backup completed successfully"
```

### üîß Environment & Security:

#### .env.example:
```bash
# Application
ENVIRONMENT=production
SECRET_KEY=your-secret-key-here
JWT_SECRET=your-jwt-secret-here

# Database
DB_PASSWORD=secure-db-password
DATABASE_URL=postgresql://freqtrade:${DB_PASSWORD}@db:5432/freqtrade

# Redis
REDIS_PASSWORD=secure-redis-password
REDIS_URL=redis://:${REDIS_PASSWORD}@redis:6379/0

# External Services
TELEGRAM_BOT_TOKEN=your-telegram-token
GITHUB_TOKEN=your-github-token
AWS_ACCESS_KEY_ID=your-aws-key
AWS_SECRET_ACCESS_KEY=your-aws-secret
S3_BUCKET=your-backup-bucket

# Monitoring
GRAFANA_PASSWORD=secure-grafana-password

# SSL (Let's Encrypt)
SSL_EMAIL=your-email@example.com
DOMAIN=your-domain.com
```

### ‚úÖ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —ç—Ç–∞–ø–∞:

#### tests/integration/test_infrastructure.py:
```python
import pytest
import requests
import docker
from unittest.mock import patch

class TestInfrastructure:
    def test_api_health_check(self):
        """Test API health endpoint"""
        response = requests.get("http://localhost:8000/health")
        assert response.status_code == 200
        assert response.json() == {"status": "healthy"}

    def test_frontend_access(self):
        """Test frontend accessibility"""
        response = requests.get("http://localhost")
        assert response.status_code == 200
        assert "Freqtrade" in response.text

    def test_database_connection(self):
        """Test database connectivity"""
        # Test database connection logic
        pass

    def test_redis_connection(self):
        """Test Redis connectivity"""
        # Test Redis connection logic
        pass

    def test_monitoring_endpoints(self):
        """Test monitoring endpoints"""
        # Prometheus
        response = requests.get("http://localhost:9090/-/healthy")
        assert response.status_code == 200

        # Grafana
        response = requests.get("http://localhost:3000/api/health")
        assert response.status_code == 200

    @patch('docker.APIClient')
    def test_docker_services_running(self, mock_docker):
        """Test that all Docker services are running"""
        client = docker.APIClient()
        containers = client.containers()

        expected_services = [
            'freqtrade_api',
            'freqtrade_db',
            'freqtrade_redis',
            'freqtrade_frontend',
            'freqtrade_nginx',
            'freqtrade_prometheus',
            'freqtrade_grafana'
        ]

        running_containers = [c['Names'][0].lstrip('/') for c in containers if c['State'] == 'running']

        for service in expected_services:
            assert service in running_containers

    def test_ssl_configuration(self):
        """Test SSL/TLS configuration"""
        response = requests.get("https://localhost", verify=False)
        assert response.status_code == 200
        # Check SSL certificate
        assert response.raw.connection.sock.getpeercert() is not None

    def test_backup_system(self):
        """Test backup system functionality"""
        # Test backup creation
        # Test backup upload to S3
        # Test backup cleanup
        pass
```

### üìä –ö–†–ò–¢–ï–†–ò–ò –ì–û–¢–û–í–ù–û–°–¢–ò –≠–¢–ê–ü–ê 6

### ‚úÖ –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è:
- [x] Docker Compose —Å 9 —Å–µ—Ä–≤–∏—Å–∞–º–∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω
- [x] Prometheus + Grafana + Loki –¥–ª—è monitoring
- [x] Nginx —Å SSL –∏ security headers
- [x] Automated backup —Å–∏—Å—Ç–µ–º–∞
- [x] Resource limits –∏ health checks

### ‚úÖ –§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è:
- [x] `docker-compose up -d` –∑–∞–ø—É—Å–∫–∞–µ—Ç –≤—Å–µ —Å–µ—Ä–≤–∏—Å—ã
- [x] –í—Å–µ health checks –ø—Ä–æ—Ö–æ–¥—è—Ç
- [x] Monitoring dashboards –¥–æ—Å—Ç—É–ø–Ω—ã
- [x] SSL —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç—ã —Ä–∞–±–æ—Ç–∞—é—Ç
- [x] Backup —Å–∫—Ä–∏–ø—Ç—ã –≤—ã–ø–æ–ª–Ω—è—é—Ç—Å—è

---

## üöÄ –°–õ–ï–î–£–Æ–©–ò–ï –®–ê–ì–ò

**–ü–µ—Ä–µ—Ö–æ–¥ –∫ –≠—Ç–∞–ø—É 7:** [Testing & QA - Comprehensive Testing](07_testing_qa.md)

**–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ–¥ –ø–µ—Ä–µ—Ö–æ–¥–æ–º:**
```bash
# –í—Å–µ –∫–æ–º–∞–Ω–¥—ã –¥–æ–ª–∂–Ω—ã –≤—ã–ø–æ–ª–Ω—è—Ç—å—Å—è –±–µ–∑ –æ—à–∏–±–æ–∫
docker-compose ps
docker-compose exec api curl -f http://localhost:8000/health
docker-compose logs --tail=10
```

---

*–≠—Ç–∞–ø 6 –∑–∞–≤–µ—Ä—à–µ–Ω: Production infrastructure —Å monitoring –≥–æ—Ç–æ–≤–∞*